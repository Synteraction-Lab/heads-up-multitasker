{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7fcb9a",
   "metadata": {},
   "source": [
    "# Grid Search using 50% Human Data, then Evaluate on other half"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f35b7",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e24ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import anderson_ksamp\n",
    "\n",
    "# Get data source\n",
    "data_dir = 'data_process/12-06/'\n",
    "\n",
    "# Simulated data (full model and before parameter inference)\n",
    "simulated_results = data_dir + '0827_simulation_result_100m_50ep.csv'\n",
    "# Human data\n",
    "human_duration_data = data_dir + 'human_data_rr_error_rate.csv'\n",
    "human_error_rate_data = data_dir + 'human_data_rr_time_cost.csv'\n",
    "\n",
    "# Read in as dataframe.\n",
    "df_simulations = pd.read_csv(simulated_results)\n",
    "human_duration_df = pd.read_csv(human_duration_data)\n",
    "human_error_rate_df = pd.read_csv(human_error_rate_data)\n",
    "\n",
    "params = {\n",
    "    'init_delta_t':None,\n",
    "    'init_sigma_position_memory':None,\n",
    "    'weight_memory_decay':None,\n",
    "    'spatial_dist_coeff':None,\n",
    "}\n",
    "\n",
    "# Control the conditions\n",
    "# Metrics\n",
    "layouts = ['L100']\n",
    "metrics = ['steps', 'error']\n",
    "# Pre-defined parameters\n",
    "prior_work_init_sigma_position_memory = 4.5\n",
    "empirical_init_delta_time = 1\n",
    "\n",
    "# Get individual-level human data\n",
    "human_duration_data = [human_duration_df[col].tolist() for col in human_duration_df.columns if col != \"Participant\"]\n",
    "human_error_data = [human_error_rate_df[col].tolist() for col in human_error_rate_df.columns if col != \"Participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1dac23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.988023952,\n",
       "  1.41509434,\n",
       "  2.631578947,\n",
       "  2.189781002,\n",
       "  4.195804196,\n",
       "  6.41025641,\n",
       "  1.515151515,\n",
       "  1.19047619,\n",
       "  1.449275362,\n",
       "  2.547770701,\n",
       "  1.052631579,\n",
       "  0.510204082,\n",
       "  1.25,\n",
       "  0.0,\n",
       "  0.546448087,\n",
       "  0.0,\n",
       "  2.962962963,\n",
       "  0.0,\n",
       "  2.491103203,\n",
       "  2.93040293,\n",
       "  2.95202952,\n",
       "  2.830188679,\n",
       "  1.342281879,\n",
       "  0.64516129,\n",
       "  2.02020202,\n",
       "  2.631578947,\n",
       "  3.418803419,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_duration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b49935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.5,\n",
       "  1.375,\n",
       "  1.375,\n",
       "  1.625,\n",
       "  2.125,\n",
       "  0.857142857,\n",
       "  1.625,\n",
       "  1.625,\n",
       "  1.5,\n",
       "  1.75,\n",
       "  1.875,\n",
       "  1.0,\n",
       "  1.625,\n",
       "  1.625,\n",
       "  1.5,\n",
       "  2.125,\n",
       "  2.125,\n",
       "  2.375,\n",
       "  1.0,\n",
       "  1.125,\n",
       "  1.25,\n",
       "  1.625,\n",
       "  1.375,\n",
       "  1.25,\n",
       "  2.125,\n",
       "  1.25,\n",
       "  1.625,\n",
       "  1.5,\n",
       "  0.875,\n",
       "  1.125]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_error_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b7f49",
   "metadata": {},
   "source": [
    "## Halve the human data into two parts - training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34d6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize a list\n",
    "def normalize(lst):\n",
    "    min_val = min(lst)\n",
    "    max_val = max(lst)\n",
    "    if min_val == max_val:  # Avoid division by zero\n",
    "        return [0.5 for _ in lst]  # Return 0.5 (middle) if all values are same\n",
    "    return [(x - min_val) / (max_val - min_val) for x in lst]\n",
    "\n",
    "# Define the cost function\n",
    "def compute_cost(sim_data, human_data):\n",
    "    return sum(abs(sim - human) for sim, human in zip(sim_data, human_data))\n",
    "\n",
    "def find_best_params(data, human_duration, human_error):\n",
    "    # Filter the main dataframe according to the pre-defined parameters\n",
    "    data = data[\n",
    "        (data['init_sigma_position_memory'] == prior_work_init_sigma_position_memory) \n",
    "        & (data['init_delta_t'] == empirical_init_delta_time)\n",
    "    ]\n",
    "    \n",
    "    data_before_params_inf = data.copy()\n",
    "    \n",
    "    unique_params = data.drop(columns=['layout', 'steps', 'error']).drop_duplicates()\n",
    "    min_cost = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for index, row in unique_params.iterrows():\n",
    "        filtered_df = data[\n",
    "#             (data['init_delta_t'] == row['init_delta_t']) &\n",
    "#             (data['init_sigma_position_memory'] == row['init_sigma_position_memory']) &\n",
    "            (data['weight_memory_decay'] == row['weight_memory_decay']) &\n",
    "            (data['spatial_dist_coeff'] == row['spatial_dist_coeff'])\n",
    "        ]\n",
    "        \n",
    "        sim_steps = [filtered_df[filtered_df['layout'] == layout]['steps'].values[0] for layout in layouts]\n",
    "        sim_error = [filtered_df[filtered_df['layout'] == layout]['error'].values[0] for layout in layouts]\n",
    "        \n",
    "        cost_steps = compute_cost(normalize(sim_steps), normalize(human_duration))\n",
    "        cost_error = compute_cost(normalize(sim_error), normalize(human_error))\n",
    "        \n",
    "        total_cost = cost_steps + cost_error\n",
    "\n",
    "        if total_cost < min_cost:\n",
    "            min_cost = total_cost\n",
    "            best_params = row\n",
    "    \n",
    "    # Given the best parameters and teh dataframe, return the simulated steps (durations) and errors for the three layouts\n",
    "    sim_steps_best = []\n",
    "    sim_errors_best = []\n",
    "    \n",
    "    # Extract the simulated steps and error for each layout based on best_params\n",
    "    for layout in layouts:\n",
    "        filtered_df = data[\n",
    "#             (data['init_delta_t'] == best_params['init_delta_t']) &\n",
    "#             (data['init_sigma_position_memory'] == best_params['init_sigma_position_memory']) &\n",
    "            (data['weight_memory_decay'] == best_params['weight_memory_decay']) &\n",
    "            (data['spatial_dist_coeff'] == best_params['spatial_dist_coeff']) &\n",
    "            (data['layout'] == layout)\n",
    "        ]\n",
    "        \n",
    "        sim_steps_best.append(filtered_df['steps'].values[0])\n",
    "        sim_errors_best.append(filtered_df['error'].values[0])\n",
    "\n",
    "    return best_params, min_cost, sim_steps_best, sim_errors_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b338b37",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80276b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.4 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_iterations = 500\n",
    "all_costs = []\n",
    "all_best_params = []\n",
    "\n",
    "# Lists to store sim-to-real mapping ratios for each iteration\n",
    "sim_to_real_ratios_duration = []\n",
    "sim_to_real_ratios_error = []\n",
    "\n",
    "# Initialize dictionaries for storing results\n",
    "simulated_durations = {'L100': []}\n",
    "simulated_errors = {'L100': []}\n",
    "human_train_durations = {'L100': []}\n",
    "human_train_errors = {'L100': []}\n",
    "human_test_durations = {'L100': []}\n",
    "human_test_errors = {'L100': []}\n",
    "human_train_durations_details = {'L100': []}  # Collect detailed data in each iterations, not aggregated\n",
    "human_train_errors_details = {'L100': []}\n",
    "human_test_durations_details = {'L100': []}\n",
    "human_test_errors_details = {'L100': []}\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Number of participants\n",
    "    num_participants = len(human_duration_data[0])\n",
    "\n",
    "    # Generate list of indices based on participants\n",
    "    indices = list(range(num_participants))\n",
    "\n",
    "    # Split indices to ensure consistency\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=0.5, random_state=i)  \n",
    "    # using i as the seed for reproducibility\n",
    "\n",
    "    # Use these indices to split the human data consistently across participants\n",
    "    def split_data_based_on_indices(data, train_indices, test_indices):\n",
    "        train_set = [data[i] for i in train_indices]\n",
    "        test_set = [data[i] for i in test_indices]\n",
    "        return train_set, test_set\n",
    "\n",
    "    # Split human duration data\n",
    "    train_duration = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_duration_data]\n",
    "    train_duration = list(zip(*train_duration))[0]  # Extracting the training data\n",
    "\n",
    "    test_duration = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_duration_data]\n",
    "    test_duration = list(zip(*test_duration))[1]  # Extracting the test data\n",
    "\n",
    "    # Split human error data\n",
    "    train_error = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_error_data]\n",
    "    train_error = list(zip(*train_error))[0]  # Extracting the training data\n",
    "\n",
    "    test_error = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_error_data]\n",
    "    test_error = list(zip(*test_error))[1]  # Extracting the test data\n",
    "\n",
    "    # Compute mean for the training and test sets\n",
    "    mean_train_duration = [np.mean(data) for data in train_duration]\n",
    "    mean_train_error = [np.mean(data) for data in train_error]\n",
    "    mean_test_duration = [np.mean(data) for data in test_duration]\n",
    "    mean_test_error = [np.mean(data) for data in test_error]\n",
    "\n",
    "    # Using the function to find the best parameters\n",
    "    best_params, _, sim_durations, sim_errors = find_best_params(df_simulations, mean_train_duration, mean_train_error)\n",
    "    all_best_params.append(best_params)\n",
    "    \n",
    "    # Get sim to real mapping ratios for duration and error metrics respectively\n",
    "    # Compute sim-to-real ratio for the current iteration\n",
    "    sim_to_real_ratio_duration = sum(mean_train_duration) / sum(sim_durations)\n",
    "    sim_to_real_ratio_error = sum(mean_train_error) / sum(sim_errors)\n",
    "    \n",
    "    # Store the computed ratios\n",
    "    sim_to_real_ratios_duration.append(sim_to_real_ratio_duration)\n",
    "    sim_to_real_ratios_error.append(sim_to_real_ratio_error)\n",
    "    \n",
    "    for label, sd, se, ted, tee, trd, tre in zip(\n",
    "        ['L100'], \n",
    "        sim_durations, \n",
    "        sim_errors, \n",
    "        test_duration, \n",
    "        test_error, \n",
    "        train_duration, \n",
    "        train_error,\n",
    "    ):\n",
    "        simulated_durations[label].append(sd)\n",
    "        simulated_errors[label].append(se)\n",
    "        human_train_durations[label].append(np.mean(trd))\n",
    "        human_train_errors[label].append(np.mean(tre))\n",
    "        human_test_durations[label].append(np.mean(ted))\n",
    "        human_test_errors[label].append(np.mean(tee))\n",
    "        human_train_durations_details[label].append(trd)\n",
    "        human_train_errors_details[label].append(tre)\n",
    "        human_test_durations_details[label].append(ted)\n",
    "        human_test_errors_details[label].append(tee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e269668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results for reproducibility\n",
    "import copy\n",
    "\n",
    "simulated_durations_copy = copy.deepcopy(simulated_durations)\n",
    "simulated_errors_copy = copy.deepcopy(simulated_errors)\n",
    "human_test_durations_copy = copy.deepcopy(human_test_durations)\n",
    "human_test_errors_copy = copy.deepcopy(human_test_errors)\n",
    "human_train_durations_copy = copy.deepcopy(human_train_durations)\n",
    "human_train_errors_copy = copy.deepcopy(human_train_errors)\n",
    "human_test_durations_details_copy = copy.deepcopy(human_test_durations_details)\n",
    "human_test_errors_details_copy = copy.deepcopy(human_test_errors_details)\n",
    "human_train_durations_details_copy = copy.deepcopy(human_train_durations_details)\n",
    "human_train_errors_details_copy = copy.deepcopy(human_train_errors_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5e9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Open a CSV file in write mode\n",
    "best_params_file_name = data_dir + \"afterPI_rr_1204_1initdeltat_4dot5sigmapm_train_test_split_repeats_data_rep500.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b07b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "with open(best_params_file_name, \"w\", newline='') as csvfile:\n",
    "    # Initialize the CSV writer\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the headers\n",
    "    headers = [\n",
    "        \"Layout\", \n",
    "        \"Simulated Durations\", \n",
    "        \"Simulated Errors\", \n",
    "        \"Simulated and Tuned Durations\",\n",
    "        \"Simulated and Tuned Errors\",\n",
    "        \"Human Train Durations\", \n",
    "        \"Human Train Errors\", \n",
    "        \"Human Test Durations\",\n",
    "        \"Human Test Errors\",\n",
    "        \"init_delta_t\", \n",
    "        \"init_sigma_position_memory\", \n",
    "        \"weight_memory_decay\", \n",
    "        \"spatial_dist_coeff\",\n",
    "        \"Sim to Real Ratio Duration\",\n",
    "        \"Sim to Real Ratio Error\"\n",
    "    ]\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Write data for each layout\n",
    "    for i, best_param in enumerate(all_best_params):\n",
    "        for label in ['L100']:\n",
    "            row = [\n",
    "                label, \n",
    "                simulated_durations[label][i], \n",
    "                simulated_errors[label][i],\n",
    "                simulated_durations[label][i] * sim_to_real_ratios_duration[i],\n",
    "                simulated_errors[label][i] * sim_to_real_ratios_error[i],\n",
    "                human_train_durations[label][i], \n",
    "                human_train_errors[label][i],\n",
    "                human_test_durations[label][i],\n",
    "                human_test_errors[label][i],\n",
    "                best_param[0],  # init_delta_t\n",
    "                best_param[1],  # init_sigma_position_memory\n",
    "                best_param[2],  # weight_memory_decay\n",
    "                best_param[3],  # spatial_dist_coeff\n",
    "                sim_to_real_ratios_duration[i],\n",
    "                sim_to_real_ratios_error[i]\n",
    "            ]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea121517",
   "metadata": {},
   "source": [
    "## Data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f638a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# best_params_file_name = \"study3_readingresumption/1118_normal_oneinitdeltat_4dot5sigmapm_train_test_split_repeats_data_rep500.csv\"\n",
    "\n",
    "# Read in the CSV file\n",
    "data = pd.read_csv(best_params_file_name)\n",
    "\n",
    "# Create dictionaries to store data by layout and type\n",
    "simulated_durations = {'L100': []}\n",
    "simulated_errors = {'L100': []}\n",
    "human_train_durations = {'L100': []}\n",
    "human_train_errors = {'L100': []}\n",
    "human_test_durations = {'L100': []}\n",
    "human_test_errors = {'L100': []}\n",
    "sim_to_real_ratios_duration = {'L100': []}\n",
    "sim_to_real_ratios_error = {'L100': []}\n",
    "# sim_to_real_ratios_duration = []\n",
    "# sim_to_real_ratios_error = []\n",
    "\n",
    "# Iterate through each row in the dataset\n",
    "for index, row in data.iterrows():\n",
    "    layout = row['Layout']\n",
    "    simulated_durations[layout].append(row['Simulated Durations'])\n",
    "    simulated_errors[layout].append(row['Simulated Errors'])\n",
    "    human_train_durations[layout].append(row['Human Train Durations'])\n",
    "    human_train_errors[layout].append(row['Human Train Errors'])\n",
    "    human_test_durations[layout].append(row['Human Test Durations'])\n",
    "    human_test_errors[layout].append(row['Human Test Errors'])\n",
    "    sim_to_real_ratios_duration[layout].append(row['Sim to Real Ratio Duration'])\n",
    "    sim_to_real_ratios_error[layout].append(row['Sim to Real Ratio Error'])\n",
    "\n",
    "num_iterations = int(data.shape[0] / len(layouts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d90e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "simulated_durations_copy = copy.deepcopy(simulated_durations)\n",
    "simulated_errors_copy = copy.deepcopy(simulated_errors)\n",
    "human_test_durations_copy = copy.deepcopy(human_test_durations)\n",
    "human_test_errors_copy = copy.deepcopy(human_test_errors)\n",
    "human_train_durations_copy = copy.deepcopy(human_train_durations)\n",
    "human_train_errors_copy = copy.deepcopy(human_train_errors)\n",
    "\n",
    "labels = ['L100']\n",
    "\n",
    "# Calculate SEM\n",
    "def std(data):\n",
    "    return np.std(data)\n",
    "\n",
    "# Function to adjust y-limit\n",
    "def adjust_ylim(ax, means, sems):\n",
    "    y_max = max([mean + sem for mean, sem in zip(means, sems)])\n",
    "    ax.set_ylim(0, y_max * 1.15)  # Adding a bit of margin to the top\n",
    "\n",
    "# Using the average results for the test set\n",
    "mean_human_test_duration = [np.mean(human_test_durations_copy[label]) for label in labels]\n",
    "std_human_test_duration = [std(human_test_durations_copy[label]) for label in labels]\n",
    "mean_human_test_error = [np.mean(human_test_errors_copy[label]) for label in labels]\n",
    "std_human_test_error = [std(human_test_errors_copy[label]) for label in labels]\n",
    "\n",
    "# Adjust the simulated data with ratios\n",
    "for iteration in range(num_iterations):\n",
    "    for label in labels:\n",
    "        simulated_durations_copy[label][iteration] *= sim_to_real_ratios_duration[layout][iteration]\n",
    "        simulated_errors_copy[label][iteration] *= sim_to_real_ratios_error[layout][iteration]\n",
    "\n",
    "# Now recompute the mean and sem for these adjusted simulated results\n",
    "mean_simulated_duration = [np.mean(simulated_durations_copy[label]) for label in labels]\n",
    "std_simulated_duration = [std(simulated_durations_copy[label]) for label in labels]\n",
    "mean_simulated_error = [np.mean(simulated_errors_copy[label]) for label in labels]\n",
    "std_simulated_error = [std(simulated_errors_copy[label]) for label in labels]\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "# # Update the plotting logic\n",
    "# x = np.arange(len(labels))\n",
    "# width = 0.2\n",
    "\n",
    "# fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "\n",
    "# # Plot for Duration\n",
    "# rects1 = ax[0].bar(x - width/2, mean_human_test_duration, width, label='Human Data', color='blue', yerr=std_human_test_duration, capsize=10)\n",
    "# rects2 = ax[0].bar(x + width/2, mean_simulated_duration, width, label='Simulated Data', color='green', yerr=std_simulated_duration, capsize=10)\n",
    "\n",
    "# # Plot for Error\n",
    "# rects3 = ax[1].bar(x - width/2, mean_human_test_error, width, label='Human Data', color='blue', yerr=std_human_test_error, capsize=10)\n",
    "# rects4 = ax[1].bar(x + width/2, mean_simulated_error, width, label='Simulated Data', color='green', yerr=std_simulated_error, capsize=10)\n",
    "\n",
    "# # Annotating bars\n",
    "# for i, (rect1, rect2) in enumerate(zip(rects1, rects2)):\n",
    "#     height1 = rect1.get_height()\n",
    "#     height2 = rect2.get_height()\n",
    "#     std1 = std_human_test_duration[i]\n",
    "#     std2 = std_simulated_duration[i]\n",
    "#     ax[0].annotate(f\"{height1:.2f}\\n({std1:.2f})\", \n",
    "#                    (rect1.get_x() + rect1.get_width() / 2., height1 + std1 + 0.05),\n",
    "#                    ha='center', va='bottom')\n",
    "#     ax[0].annotate(f\"{height2:.2f}\\n({std2:.2f})\", \n",
    "#                    (rect2.get_x() + rect2.get_width() / 2., height2 + std2 + 0.05),\n",
    "#                    ha='center', va='bottom')\n",
    "\n",
    "# for i, (rect3, rect4) in enumerate(zip(rects3, rects4)):\n",
    "#     height3 = rect3.get_height()\n",
    "#     height4 = rect4.get_height()\n",
    "#     std3 = std_human_test_error[i]\n",
    "#     std4 = std_simulated_error[i]\n",
    "#     ax[1].annotate(f\"{height3:.2f}\\n({std3:.2f})\", \n",
    "#                    (rect3.get_x() + rect3.get_width() / 2., height3 + std3 + 0.05),\n",
    "#                    ha='center', va='bottom')\n",
    "#     ax[1].annotate(f\"{height4:.2f}\\n({std4:.2f})\", \n",
    "#                    (rect4.get_x() + rect4.get_width() / 2., height4 + std4 + 0.05),\n",
    "#                    ha='center', va='bottom')\n",
    "\n",
    "# # Labels, title, and custom x-axis tick labels\n",
    "# ax[0].set_ylabel('Reading Resumption Time (s)')\n",
    "# ax[0].set_xticks(x)\n",
    "# ax[0].set_xticklabels(labels)\n",
    "# ax[0].legend(fontsize=15)\n",
    "# adjust_ylim(ax[0], mean_human_test_duration + mean_simulated_duration, std_human_test_duration + std_simulated_duration)\n",
    "\n",
    "# ax[1].set_ylabel('Reading Resumption Error Rate (%)')\n",
    "# ax[1].set_xticks(x)\n",
    "# ax[1].set_xticklabels(labels)\n",
    "# ax[1].legend(fontsize=15)\n",
    "# adjust_ylim(ax[1], mean_human_test_error + mean_simulated_error, std_human_test_error + std_simulated_error)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb547c21",
   "metadata": {},
   "source": [
    "### Save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19b7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.5])\n",
    "width = 0.2\n",
    "\n",
    "fig_duration, ax_duration = plt.subplots(figsize=(6, 4))\n",
    "rects1 = ax_duration.bar(x - width/2, mean_human_test_duration, width, label='Human Data', color='blue', yerr=std_human_test_duration, capsize=10)\n",
    "rects2 = ax_duration.bar(x + width/2, mean_simulated_duration, width, label='Simulated Data', color='green', yerr=std_simulated_duration, capsize=10)\n",
    "\n",
    "# Annotations for Duration plot\n",
    "for i, (rect1, rect2) in enumerate(zip(rects1, rects2)):\n",
    "    height1 = rect1.get_height()\n",
    "    height2 = rect2.get_height()\n",
    "    std1 = std_human_test_duration[i]\n",
    "    std2 = std_simulated_duration[i]\n",
    "    ax_duration.annotate(f\"{height1:.2f}\\n({std1:.2f})\", \n",
    "                   (rect1.get_x() + rect1.get_width() / 2., height1 + std1 + 0.05),\n",
    "                   ha='center', va='bottom')\n",
    "    ax_duration.annotate(f\"{height2:.2f}\\n({std2:.2f})\", \n",
    "                   (rect2.get_x() + rect2.get_width() / 2., height2 + std2 + 0.05),\n",
    "                   ha='center', va='bottom')\n",
    "\n",
    "# Labels for Duration plot\n",
    "ax_duration.set_ylabel('Reading Resumption Time (s)', fontsize=14)\n",
    "ax_duration.set_xticks(x)\n",
    "ax_duration.set_xticklabels(labels, fontsize=12, fontweight='bold')\n",
    "ax_duration.tick_params(axis='y', labelsize=14)  # Adjust the fontsize as desired for y-axis\n",
    "\n",
    "ax_duration.legend(fontsize=15)\n",
    "adjust_ylim(ax_duration, mean_human_test_duration + mean_simulated_duration, std_human_test_duration + std_simulated_duration)\n",
    "\n",
    "# Also, if you want the axis tick numbers to be larger:\n",
    "ax_duration.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "# fig_duration.tight_layout()\n",
    "fig_duration.savefig(data_dir + 'study4readingresumptiontimecost.png', dpi=300)\n",
    "plt.close(fig_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d81a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_error, ax_error = plt.subplots(figsize=(6, 4))\n",
    "rects3 = ax_error.bar(x - width/2, mean_human_test_error, width, label='Human Data', color='blue', yerr=std_human_test_error, capsize=10)\n",
    "rects4 = ax_error.bar(x + width/2, mean_simulated_error, width, label='Simulated Data', color='green', yerr=std_simulated_error, capsize=10)\n",
    "\n",
    "# Annotations for Error plot\n",
    "for i, (rect3, rect4) in enumerate(zip(rects3, rects4)):\n",
    "    height3 = rect3.get_height()\n",
    "    height4 = rect4.get_height()\n",
    "    std3 = std_human_test_error[i]\n",
    "    std4 = std_simulated_error[i]\n",
    "    ax_error.annotate(f\"{height3:.2f}\\n({std3:.2f})\", \n",
    "                   (rect3.get_x() + rect3.get_width() / 2., height3 + std3 + 0.05),\n",
    "                   ha='center', va='bottom')\n",
    "    ax_error.annotate(f\"{height4:.2f}\\n({std4:.2f})\", \n",
    "                   (rect4.get_x() + rect4.get_width() / 2., height4 + std4 + 0.05),\n",
    "                   ha='center', va='bottom')\n",
    "\n",
    "# Labels for Error plot\n",
    "ax_error.set_ylabel('Reading Resumption Error Rate (%)', fontsize=14)\n",
    "ax_error.tick_params(axis='y', labelsize=14)  # Adjust the fontsize as desired for y-axis\n",
    "ax_error.set_xticks(x)\n",
    "ax_error.set_xticklabels(labels, fontsize=12, fontweight='bold')\n",
    "ax_error.legend(fontsize=15)\n",
    "adjust_ylim(ax_error, mean_human_test_error + mean_simulated_error, std_human_test_error + std_simulated_error)\n",
    "\n",
    "# Also, if you want the axis tick numbers to be larger:\n",
    "ax_duration.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "fig_error.tight_layout()\n",
    "\n",
    "# fig_error.tight_layout()\n",
    "fig_error.savefig(data_dir + 'study4readingresumptionerrorrate.png', dpi=300)\n",
    "plt.close(fig_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136d311",
   "metadata": {},
   "source": [
    "### RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ceeb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the CSV file\n",
    "data = pd.read_csv(best_params_file_name)\n",
    "\n",
    "# Create dictionaries to store data by layout and type\n",
    "simulated_durations = {'L100': []}\n",
    "simulated_errors = {'L100': []}\n",
    "simulated_tuned_durations = {'L100': []}\n",
    "simulated_tuned_errors = {'L100': []}\n",
    "human_train_durations = {'L100': []}\n",
    "human_train_errors = {'L100': []}\n",
    "human_test_durations = {'L100': []}\n",
    "human_test_errors = {'L100': []}\n",
    "sim_to_real_ratios_duration = {'L100': []}\n",
    "sim_to_real_ratios_error = {'L100': []}\n",
    "# sim_to_real_ratios_duration = []\n",
    "# sim_to_real_ratios_error = []\n",
    "\n",
    "# Iterate through each row in the dataset\n",
    "for index, row in data.iterrows():\n",
    "    layout = row['Layout']\n",
    "    simulated_durations[layout].append(row['Simulated Durations'])\n",
    "    simulated_errors[layout].append(row['Simulated Errors'])\n",
    "    simulated_tuned_durations[layout].append(row['Simulated and Tuned Durations'])\n",
    "    simulated_tuned_errors[layout].append(row['Simulated and Tuned Errors'])\n",
    "    human_train_durations[layout].append(row['Human Train Durations'])\n",
    "    human_train_errors[layout].append(row['Human Train Errors'])\n",
    "    human_test_durations[layout].append(row['Human Test Durations'])\n",
    "    human_test_errors[layout].append(row['Human Test Errors'])\n",
    "    sim_to_real_ratios_duration[layout].append(row['Sim to Real Ratio Duration'])\n",
    "    sim_to_real_ratios_error[layout].append(row['Sim to Real Ratio Error'])\n",
    "\n",
    "num_iterations = int(data.shape[0] / len(layouts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2929ad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE between simulated durations and human test durations: 0.6288\n",
      "Average RMSE between simulated errors and human test errors: 0.1373\n",
      "RMSE for L100 - Durations: 0.6288, Errors: 0.1373\n",
      "Average error rate is on scale: 1.5198404761858666\n"
     ]
    }
   ],
   "source": [
    "# Get rsme\n",
    "simulated_durations_copy = copy.deepcopy(simulated_durations)\n",
    "simulated_errors_copy = copy.deepcopy(simulated_errors)\n",
    "human_test_durations_copy = copy.deepcopy(human_test_durations)\n",
    "human_test_errors_copy = copy.deepcopy(human_test_errors)\n",
    "human_train_durations_copy = copy.deepcopy(human_train_durations)\n",
    "human_train_errors_copy = copy.deepcopy(human_train_errors)\n",
    "human_test_durations_details_copy = copy.deepcopy(human_test_durations_details)\n",
    "human_test_errors_details_copy = copy.deepcopy(human_test_errors_details)\n",
    "human_train_durations_details_copy = copy.deepcopy(human_train_durations_details)\n",
    "human_train_errors_details_copy = copy.deepcopy(human_train_errors_details)\n",
    "\n",
    "\n",
    "# Adjust the simulated data with ratios\n",
    "for iteration in range(num_iterations):\n",
    "    for label in labels:\n",
    "        simulated_durations_copy[label][iteration] *= sim_to_real_ratios_duration[label][iteration]\n",
    "        simulated_errors_copy[label][iteration] *= sim_to_real_ratios_error[label][iteration]\n",
    "\n",
    "# RMSE computation function\n",
    "def compute_rmse(true_vals, predicted_vals):\n",
    "    return np.sqrt(np.mean((np.array(true_vals) - np.array(predicted_vals)) ** 2))\n",
    "\n",
    "# Compute RMSE for durations and errors for each layout\n",
    "rmse_durations_layouts = {}\n",
    "rmse_errors_layouts = {}\n",
    "\n",
    "for label in labels:\n",
    "    rmse_durations_layouts[label] = compute_rmse(human_test_durations_copy[label], simulated_durations_copy[label])\n",
    "    rmse_errors_layouts[label] = compute_rmse(human_test_errors_copy[label], simulated_errors_copy[label])\n",
    "\n",
    "# Average RMSE across all layouts\n",
    "avg_rmse_durations = np.mean(list(rmse_durations_layouts.values()))\n",
    "avg_rmse_errors = np.mean(list(rmse_errors_layouts.values()))\n",
    "\n",
    "# Display results\n",
    "print(f\"Average RMSE between simulated durations and human test durations: {avg_rmse_durations:.4f}\")\n",
    "print(f\"Average RMSE between simulated errors and human test errors: {avg_rmse_errors:.4f}\")\n",
    "for label in labels:\n",
    "    print(f\"RMSE for {label} - Durations: {rmse_durations_layouts[label]:.4f}, Errors: {rmse_errors_layouts[label]:.4f}\")\n",
    "print(f\"Average error rate is on scale: {np.mean(simulated_errors_copy['L100'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fc3b0",
   "metadata": {},
   "source": [
    "### Stastical Analysis: Anderson-Darling two-sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b3e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_49176\\2323831652.py:3: UserWarning: p-value capped: true value larger than 0.25\n",
      "  time_cost_result = anderson_ksamp([human_test_durations_copy['L100'], simulated_durations_copy['L100']])\n"
     ]
    }
   ],
   "source": [
    "# Performing the Anderson-Darling two-sample test\n",
    "error_rate_result = anderson_ksamp([human_test_errors_copy['L100'], simulated_errors_copy['L100']])\n",
    "time_cost_result = anderson_ksamp([human_test_durations_copy['L100'], simulated_durations_copy['L100']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f4af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: Anderson_ksampResult(statistic=3.0076130362371427, critical_values=array([0.325, 1.226, 1.961, 2.718, 3.752, 4.592, 6.546]), pvalue=0.01934134055579504), \n",
      "Time Cost: Anderson_ksampResult(statistic=-0.29283423182056, critical_values=array([0.325, 1.226, 1.961, 2.718, 3.752, 4.592, 6.546]), pvalue=0.25)\n"
     ]
    }
   ],
   "source": [
    "print(f'Error Rate: {error_rate_result}, \\nTime Cost: {time_cost_result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
